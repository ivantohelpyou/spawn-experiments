# Future Experiments Roadmap - Hierarchical System (T.DCC)

> **LATEST**: Experiment 010-password-generator completed with 4-method comparison
> **Results**: Method timing validated - 1m17s (immediate) to 9m20s (validated TDD)

> **NEW**: Reorganized with hierarchical numbering system (T.DCC format)
> See [EXPERIMENT_NUMBERING_SYSTEM.md](EXPERIMENT_NUMBERING_SYSTEM.md) for complete mapping

## Current Status

### Completed Experiments (Versioned Numbering)
1. **1.201.0** - Expression Evaluator (Math/Parsing) - 35 min total
2. **1.203.0** - Simple Interest Calculator (Basic Math/CLI) - Smoke test
3. **1.301** - LRU Cache with TTL (Data Structures) - âŒ **STOPPED** - Methods 3&4 hit token limits, incomplete
4. **1.302.0** - LRU Cache with TTL (Data Structures/Performance) - âœ… **COMPLETE** - 6-13 min per method, successful parallel execution
5. **1.102.0** - Multilingual Word Counter (String Processing) - âœ… **COMPLETE** - validation methodology successful
6. **1.401.0** - Password Generator (Security/Crypto) - âœ… **COMPLETE** - Tier 1 validation
7. **1.205.0** - Prime Number Generator (Mathematical) - âœ… **COMPLETE** - methodology comparison successful
8. **1.101.0** - Anagram Grouper (String Processing) - âœ… **COMPLETE** - TDD won with 3X less code
9. **1.103.0** - Roman Numeral Converter (String Processing) - âœ… **COMPLETE** - fastest TDD at 3m 37s
10. **1.104.0** - Balanced Parentheses (String Processing) - âœ… **COMPLETE** - Tier 1 series concluded
11. **1.501** - Email Validator (Input Validation) - âœ… **COMPLETE** - 3.6X code reduction with TDD
12. **1.502** - URL Validator (Input Validation) - âœ… **COMPLETE** - 32.3X over-engineering discovered!
13. **1.503** - File Path Validator + Competition Injection - âœ… **COMPLETE** - ðŸš¨ **BREAKTHROUGH: Reversible over-engineering proven!**

*Legacy numbers: 002â†’1.201.0, 006â†’1.203.0, 007â†’1.301(STOPPED), 008â†’1.302.0, 009â†’1.102.0, 010â†’1.401.0, 011â†’1.205.0, 012â†’1.101.0, 013â†’1.103.0, 014â†’1.104.0*

### Key Insights Discovered
- **ðŸš¨ BREAKTHROUGH: Competition Injection Reverses Over-Engineering**: File Path (4,530â†’687 lines with constrained pressure)
- **Escalating Over-Engineering Pattern**: URL (32.3X) > File Path (22.1X) > Email (3.6X) complexity explosion
- **Enterprise AI Development Achievable**: Constrained interventions maintain both speed and documentation quality
- **AI Adaptability Under Pressure**: Proven ability to right-size methodology application while preserving integrity
- **Time Convergence**: Most methods complete in 8-14 minutes regardless of approach
- **Parallel Launch Success**: Simultaneous execution proven feasible (009)
- **Resource Constraints Impact**: Token limits significantly affected Methods 3&4 in 007
- **TDD Efficiency on Simple Problems**: Methods 3&4 produce cleaner, more efficient code for Tier 1 algorithms
- **Specification Explosion Risk**: Method 2 over-engineers simple problems (URL: 6,036 vs 187 lines!)
- **Test Validation Innovation**: Method 4's test validation methodology catches subtle bugs early
- **Methodology Selection Context-Dependent**: Different approaches optimal for different complexity tiers
- **AI Resource Usage Patterns**: TDD approaches require more tool interactions (54 vs 29 in 007)

## New Experimental Framework: Three-Tier System

Based on lessons learned, future experiments follow a **crawl-walk-run** progression:

### **Tier 1: Functions (010-019) - CRAWL**
**Scope**: Pure algorithmic problems, single functions, stdlib only
**Duration**: 5-15 minutes per approach (30-60 min total parallel)
**Claude Code Usage**: âœ… **Safe for any usage window**
**Purpose**: Isolate methodology differences without architectural complexity
**Status**: âœ… **COMPLETE** - Series 010-014 finished

#### Completed Tier 1 Experiments
- **1.401.0 - Password Generator**: âœ… Cryptographic randomness, character set manipulation
- **1.205.0 - Prime Number Generator**: âœ… Algorithm choice and optimization
- **1.101.0 - Anagram Grouper**: âœ… Hash key strategy and grouping logic - **TDD Winner**
- **1.103.0 - Roman Numeral Converter**: âœ… Mapping strategy and edge cases - **Fastest TDD**
- **1.104.0 - Balanced Parentheses**: âœ… Stack management and character matching

#### Tier 1 Extensions - Input Validation Domain (1.5XX)
**Purpose**: Bridge gap between pure algorithms and CLI tools for better composability

##### âœ… **Completed Input Validation Experiments**
- **1.501 - Email Validator**: âœ… **COMPLETE** - Revolutionary 3.6X code reduction finding, security vulnerability analysis
- **1.502 - URL Validator**: âœ… **COMPLETE** - **32.3X OVER-ENGINEERING!** Largest complexity explosion documented

##### ðŸ“‹ **Remaining Input Validation Experiments**
- **1.503 - File Path Validator**: Path format and existence validation ðŸ‘ˆ **RECOMMENDED NEXT**
- **1.504 - Date Format Validator**: Date parsing and validation patterns
- **1.505 - Phone Number Validator**: International phone number formats

**Pattern Discovery**: Escalating over-engineering factor (Email 3.6X â†’ URL 32.3X). Will File Path continue trend?

### **Tier 2: CLI Tools (020-029) - WALK**
**Scope**: Command-line utilities, file I/O, composable tools
**Duration**: 15-30 minutes per approach (60-120 min total parallel)
**Claude Code Usage**: âš ï¸ **Requires >2 hours remaining** (based on 007 resource analysis)
**Purpose**: Study interface design and component composition
**Components Available**: Discoverable functions from Tier 1 (010-014)
**Innovation**: Component discovery research - natural reuse vs. rebuild patterns

#### Planned Tier 2 Experiments (Strategic Component Alignment)
- **2.501 - Password Manager CLI**: Natural reuse of 1.401.0 password generation
- **2.201 - Number Theory Calculator**: Strategic reuse of 1.205.0 primes, 1.103.0 numerals
- **2.102 - Text Analysis Tool**: Natural reuse of 1.101.0 anagram grouping
- **2.202 - Code Structure Validator**: Strategic reuse of 1.104.0 parentheses matching
- **2.401 - File Statistics Tool**: Pure CLI tool with minimal component dependencies (baseline)

#### Component Discovery Research Framework
**Key Questions**: Which methodologies naturally discover and reuse existing components?
**Measurement**: Discovery rates, reuse depth, integration strategies by methodology
**Environment**: Components placed in discoverable locations without explicit guidance

### **Tier 3: Applications (030-039) - RUN**
**Scope**: Full applications with GUIs, APIs, persistence
**Duration**: 45-90 minutes per approach (180-360 min total parallel)
**Claude Code Usage**: âŒ **Requires >4 hours remaining** (based on 007 token analysis)
**Purpose**: Study complex system architecture and integration
**Components Available**: Functions (Tier 1) + Tools (Tier 2) discoverable
**Resource Planning**: Account for higher tool usage in Methods 3&4 (up to 54 interactions vs 29)

#### Planned Tier 3 Experiments
- **3.101 - Personal Knowledge Manager**: Note-taking with search and tagging
- **3.201 - Project Dashboard**: Development metrics and build monitoring
- **3.401 - Personal Finance Tracker**: Expense tracking with budgets and reports
- **3.301 - System Monitor**: Resource monitoring with alerts and history
- **3.102 - Document Processor**: Batch format conversion and workflow automation

## Discovered Components Research

### Key Innovation
Study **organic component discovery** patterns without explicit guidance:
- Components placed in `./utils/functions/` and `./utils/tools/`
- No mention in experiment prompts
- Natural exploration and reuse decisions measured
- Authentic development environment simulation

### Research Questions
1. **Discovery Patterns**: Which methodologies naturally explore existing codebases?
2. **Evaluation Criteria**: How do approaches assess found components for fitness?
3. **Integration Strategies**: What drives reuse vs. rebuild decisions?
4. **Architecture Influence**: How does component availability affect system design?

## Experimental Improvements

### Bias Prevention
- **Neutral naming enforced**: 1-immediate-implementation, 2-specification-driven, etc.
- **Language monitoring**: No quality indicators (naive/advanced/optimal)
- **Pre-experiment confirmation**: User validates bias-neutral setup
- **Post-experiment reporting**: Standard testing instructions with warnings

### Quality Improvements
- **Testing warnings**: Flag slow dependencies (pandas, heavy ML libs)
- **Quick test paths**: Always identify fast validation approach
- **Protocol compliance**: Transparent documentation of any violations
- **Reproducibility**: Clear instructions for result validation

## Priority Execution Plan

### Phase 1: Tier 1 Foundation (Next 2-3 months)
Execute experiments 010-014 to build function library and establish baseline methodology patterns.

### Phase 2: Tier 2 Composition (Following 2-3 months)
Execute experiments 020-024 to study tool composition and interface design with available function components.

### Phase 3: Tier 3 Integration (Final phase)
Execute experiments 030-034 to analyze complex system architecture with full component ecosystem.

## Success Metrics

### Quantitative
- **Component reuse rates** across methodologies and tiers
- **Development speed** with and without available components
- **Quality metrics** (correctness, test coverage, maintainability)
- **Architecture complexity** measures

### Qualitative
- **Natural discovery patterns** for existing components
- **Integration strategy differences** between methodologies
- **Methodology consistency** across complexity tiers
- **Realistic development behavior** patterns

## Expected Outcomes

1. **Methodology Scaling**: How approaches adapt across complexity levels
2. **Component Utilization**: Which methodologies naturally leverage existing work
3. **Architecture Emergence**: What design patterns emerge from generative development
4. **Development Efficiency**: Cumulative benefits of building block availability

This tiered approach addresses the scope ambiguity problem while providing unprecedented insight into realistic development scenarios with existing codebases.

## Future Organizational Improvements

### Hierarchical Numbering System (Proposed)
**Problem**: Current sequential numbering (010, 011, 012...) requires renumbering when inserting experiments
**Solution**: Dewey Decimal-inspired system allowing infinite extensions without renumbering

#### Proposed Structure
- **Tier 1 Functions**: 1.001, 1.002, 1.003, etc.
- **Tier 2 CLI Tools**: 2.001, 2.002, 2.003, etc.
- **Tier 3 Applications**: 3.001, 3.002, 3.003, etc.
- **Special Studies**: 4.001 (methodology comparisons), 5.001 (replication studies), etc.

#### Benefits
- **Extensible**: Insert 1.015 between 1.001 and 1.002 if needed
- **Categorical**: Tier immediately visible from number
- **Future-proof**: Supports sub-categories (1.001.1, 1.001.2 for variations)
- **Legacy Mapping**: Current 010-014 â†’ 1.001-1.005

#### Implementation Status
- **Phase 1**: âœ… **COMPLETE** - All documentation updated with new numbering system
- **Phase 2**: ðŸ”„ **OPTIONAL** - Directory symlinks for backward compatibility (future)
- **Phase 3**: âœ… **ACTIVE** - All future experiments use new numbering format
- **Phase 4**: ðŸ“š **FUTURE** - Physical directory migration (low priority)

#### Backward Compatibility Guide
**All legacy experiment references remain valid:**
- Directory names unchanged (experiments/012-anagram-grouper/)
- Legacy numbers in documentation show mapping (012 â†’ 1.101)
- GitHub links and bookmarks continue working
- Gradual transition - no breaking changes

**Quick Reference Card:**
```
002 â†’ 1.201.0 | 006 â†’ 1.203.0 | 007 â†’ 1.301(STOPPED) | 008 â†’ 1.302.0 | 009 â†’ 1.102.0
010 â†’ 1.401.0 | 011 â†’ 1.205.0 | 012 â†’ 1.101.0 | 013 â†’ 1.103.0 | 014 â†’ 1.104.0
```